# üõ°Ô∏è Toxic Content Classification

A Deep Learning & NLP-based system for detecting and classifying toxic content into multiple categories.  
This project aims to help build safer online platforms by automatically identifying harmful text.

---

## üìå Overview

Toxic content detection is a Natural Language Processing (NLP) task used in:

- Social media moderation  
- Online communities  
- Comment filtering systems  
- Chat applications  

This project builds a **multi-class text classification model** to categorize text into **9 classes**, including:

- Safe  
- Unsafe  
- Violent Crimes  
- Non-Violent Crimes  
- Harassment  
- Hate Speech  
- Sexual Content  
- Unknown S-Type  
- Other Toxic Categories  

---

## üß† Models & Techniques

The project experiments with different NLP architectures:

- LSTM / BiLSTM  
- Transformer-based models (BERT family)  
- Pretrained word embeddings  
- Fine-tuning strategies  
- Class weighting for imbalanced data  

---
